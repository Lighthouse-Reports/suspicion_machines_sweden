{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swedish Fairness Assessment v.2\n",
    "\n",
    "Author: Gabriel Geiger & Justin Braun <br>\n",
    "Date: 09-02-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "BASE_PATH = os.getcwd() + \"/\"\n",
    "RAW_DATA_PATH = BASE_PATH + \"raw_data/\"\n",
    "PROCESSED_DATA_PATH = BASE_PATH + \"processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/justin-casimirbraun/GitHub/Sweden_Fairness_v2/raw_data/... \n",
      "\n",
      "Table 'Gender 1 Decimal' loaded with shape (6129, 4)\n",
      "Table 'Income 1 Decimal' loaded with shape (6129, 4)\n",
      "Table 'Education 1 Decimal' loaded with shape (6129, 4)\n",
      "Table 'Foreign 1 Decimal' loaded with shape (6129, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Gender 1 Decimal':        Selection Method                 Result Risk Score Gender\n",
       " 0             High Risk           Errors Found        0.2      M\n",
       " 1     Follow-up Control           Errors Found                 M\n",
       " 2        High High Risk  Control Investigation        0.1      K\n",
       " 3                Random        No Errors Found                 M\n",
       " 4                Random        No Errors Found                 K\n",
       " ...                 ...                    ...        ...    ...\n",
       " 6124          High Risk        No Errors Found        0.1      K\n",
       " 6125          High Risk           Errors Found        0.2      K\n",
       " 6126             Random           Errors Found                 K\n",
       " 6127          High Risk           Errors Found        0.1      K\n",
       " 6128          High Risk        No Errors Found        0.2      M\n",
       " \n",
       " [6129 rows x 4 columns],\n",
       " 'Income 1 Decimal':        Selection Method                    Result Risk Score  Income\n",
       " 0             High Risk           No Errors Found        0.2  220000\n",
       " 1                Random           No Errors Found             310000\n",
       " 2                Random           No Errors Found             400000\n",
       " 3             High Risk              Errors Found        0.2  200000\n",
       " 4             High Risk              Errors Found          0  210000\n",
       " ...                 ...                       ...        ...     ...\n",
       " 6124  Follow-up Control           No Errors Found             260000\n",
       " 6125          High Risk           No Errors Found          0  310000\n",
       " 6126     High High Risk           No Errors Found        0.2   90000\n",
       " 6127     High High Risk           No Errors Found        0.2  230000\n",
       " 6128     High High Risk  No Control Investigation        0.1  320000\n",
       " \n",
       " [6129 rows x 4 columns],\n",
       " 'Education 1 Decimal':        Selection Method                 Result Risk Score  Education\n",
       " 0             High Risk        No Errors Found          0        3.0\n",
       " 1             High Risk           Errors Found        0.1        5.0\n",
       " 2             High Risk           Errors Found        0.1        3.0\n",
       " 3             High Risk           Errors Found        0.2        2.0\n",
       " 4        High High Risk           Errors Found        0.2        2.0\n",
       " ...                 ...                    ...        ...        ...\n",
       " 6124             Random           Errors Found                   3.0\n",
       " 6125          High Risk           Errors Found        0.2        3.0\n",
       " 6126          High Risk           Errors Found        0.1        3.0\n",
       " 6127  Follow-up Control           Errors Found                   3.0\n",
       " 6128     High High Risk  Control Investigation        0.2        3.0\n",
       " \n",
       " [6129 rows x 4 columns],\n",
       " 'Foreign 1 Decimal':      Selection Method                 Result Risk Score  Born Abroad  \\\n",
       " 0      High High Risk        No Errors Found        0.1            0   \n",
       " 1           High Risk        No Errors Found          0            0   \n",
       " 2           High Risk        No Errors Found        0.2            1   \n",
       " 3              Random           Errors Found                       0   \n",
       " 4           High Risk           Errors Found        0.1            1   \n",
       " ...               ...                    ...        ...          ...   \n",
       " 6124        High Risk        No Errors Found        0.2            0   \n",
       " 6125        High Risk        No Errors Found        0.1            0   \n",
       " 6126           Random           Errors Found                       0   \n",
       " 6127        High Risk        No Errors Found        0.1            0   \n",
       " 6128   High High Risk  Control Investigation        0.2            1   \n",
       " \n",
       "       Foreign Background  \n",
       " 0                      0  \n",
       " 1                      0  \n",
       " 2                      1  \n",
       " 3                      0  \n",
       " 4                      1  \n",
       " ...                  ...  \n",
       " 6124                   0  \n",
       " 6125                   0  \n",
       " 6126                   0  \n",
       " 6127                   1  \n",
       " 6128                   1  \n",
       " \n",
       " [6129 rows x 5 columns]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load processed data stored Excel file.\n",
    "@param filename:\n",
    "@param path:\n",
    "\"\"\"\n",
    "def load_data(filename, path = RAW_DATA_PATH, filter=False):\n",
    "  print(\"Loading data from {f}... \\n\".format(f=path))\n",
    "  tables = {}\n",
    "\n",
    "  excel = pd.ExcelFile(path + filename)\n",
    "  sheet_names = excel.sheet_names\n",
    "\n",
    "  for sheet_name in sheet_names :\n",
    "\n",
    "    # We only want to get the tables with 1 decimal (e.g. no rows removed)\n",
    "    if \"1\" not in sheet_name :\n",
    "      continue\n",
    "\n",
    "    df = excel.parse(sheet_name)\n",
    "\n",
    "    tables[sheet_name] = df\n",
    "    print(\"Table '{t}' loaded with shape {s}\".format(t=sheet_name,s=df.shape))\n",
    "\n",
    "  return tables\n",
    "\n",
    "raw_tables = load_data(\"data_english.xlsx\")\n",
    "raw_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender 1 Decimal':        Selection Method           Result Risk Score Gender\n",
       " 0             High Risk     Errors Found        0.2      M\n",
       " 1     Follow-up Control     Errors Found                 M\n",
       " 2        High High Risk     Errors Found        0.1      K\n",
       " 3                Random  No Errors Found                 M\n",
       " 4                Random  No Errors Found                 K\n",
       " ...                 ...              ...        ...    ...\n",
       " 6124          High Risk  No Errors Found        0.1      K\n",
       " 6125          High Risk     Errors Found        0.2      K\n",
       " 6126             Random     Errors Found                 K\n",
       " 6127          High Risk     Errors Found        0.1      K\n",
       " 6128          High Risk  No Errors Found        0.2      M\n",
       " \n",
       " [6129 rows x 4 columns],\n",
       " 'Income 1 Decimal':        Selection Method           Result Risk Score  Income Income Level\n",
       " 0             High Risk  No Errors Found        0.2  220000   Low Income\n",
       " 1                Random  No Errors Found             310000  High Income\n",
       " 2                Random  No Errors Found             400000  High Income\n",
       " 3             High Risk     Errors Found        0.2  200000   Low Income\n",
       " 4             High Risk     Errors Found          0  210000   Low Income\n",
       " ...                 ...              ...        ...     ...          ...\n",
       " 6124  Follow-up Control  No Errors Found             260000   Low Income\n",
       " 6125          High Risk  No Errors Found          0  310000  High Income\n",
       " 6126     High High Risk  No Errors Found        0.2   90000   Low Income\n",
       " 6127     High High Risk  No Errors Found        0.2  230000   Low Income\n",
       " 6128     High High Risk     Errors Found        0.1  320000  High Income\n",
       " \n",
       " [6129 rows x 5 columns],\n",
       " 'Education 1 Decimal':        Selection Method           Result Risk Score  Education Education Level\n",
       " 0             High Risk  No Errors Found          0        3.0   Low Education\n",
       " 1             High Risk     Errors Found        0.1        5.0  High Education\n",
       " 2             High Risk     Errors Found        0.1        3.0   Low Education\n",
       " 3             High Risk     Errors Found        0.2        2.0   Low Education\n",
       " 4        High High Risk     Errors Found        0.2        2.0   Low Education\n",
       " ...                 ...              ...        ...        ...             ...\n",
       " 6124             Random     Errors Found                   3.0   Low Education\n",
       " 6125          High Risk     Errors Found        0.2        3.0   Low Education\n",
       " 6126          High Risk     Errors Found        0.1        3.0   Low Education\n",
       " 6127  Follow-up Control     Errors Found                   3.0   Low Education\n",
       " 6128     High High Risk     Errors Found        0.2        3.0   Low Education\n",
       " \n",
       " [6129 rows x 5 columns],\n",
       " 'Foreign 1 Decimal':      Selection Method           Result Risk Score  Born Abroad  \\\n",
       " 0      High High Risk  No Errors Found        0.1            0   \n",
       " 1           High Risk  No Errors Found          0            0   \n",
       " 2           High Risk  No Errors Found        0.2            1   \n",
       " 3              Random     Errors Found                       0   \n",
       " 4           High Risk     Errors Found        0.1            1   \n",
       " ...               ...              ...        ...          ...   \n",
       " 6124        High Risk  No Errors Found        0.2            0   \n",
       " 6125        High Risk  No Errors Found        0.1            0   \n",
       " 6126           Random     Errors Found                       0   \n",
       " 6127        High Risk  No Errors Found        0.1            0   \n",
       " 6128   High High Risk     Errors Found        0.2            1   \n",
       " \n",
       "       Foreign Background  \n",
       " 0                      0  \n",
       " 1                      0  \n",
       " 2                      1  \n",
       " 3                      0  \n",
       " 4                      1  \n",
       " ...                  ...  \n",
       " 6124                   0  \n",
       " 6125                   0  \n",
       " 6126                   0  \n",
       " 6127                   1  \n",
       " 6128                   1  \n",
       " \n",
       " [6129 rows x 5 columns]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_data(tables:dict) : \n",
    "\n",
    "    # Split education\n",
    "    ed_table = tables[\"Education 1 Decimal\"]\n",
    "    ed_table[\"Education Level\"] = ed_table[\"Education\"].apply(\n",
    "        lambda e: \"Low Education\" if e <= 3.0 else \"High Education\"\n",
    "    )\n",
    "    tables[\"Education 1 Decimal\"] = ed_table\n",
    "\n",
    "    # Split Income\n",
    "    income_table = tables[\"Income 1 Decimal\"]\n",
    "    median_income = income_table[\"Income\"].median()\n",
    "\n",
    "    income_table[\"Income Level\"] = income_table[\"Income\"].apply(\n",
    "        lambda i: \"High Income\" if i >= median_income else \"Low Income\"\n",
    "    )\n",
    "    tables[\"Income 1 Decimal\"] = income_table\n",
    "\n",
    "    # Merge labels\n",
    "    for key,table in tables.items() : \n",
    "\n",
    "        table[\"Result\"] = table[\"Result\"].apply(\n",
    "            lambda r : \"No Errors Found\" if r == \"No Errors Found\" else \"Errors Found\"\n",
    "        )\n",
    "\n",
    "        tables[key] = table\n",
    "    \n",
    "    return tables\n",
    "\n",
    "tables = process_data(raw_tables) \n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO:DO Create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gender : M ----\n",
      "M proportion random: 43.94\n",
      "M proportion algo: 32.49\n",
      "Percentage point difference: -11.45\n",
      "Over/under representation 0.74\n",
      "Test passed.\n",
      "\n",
      "--- Gender : K ----\n",
      "K proportion random: 56.06\n",
      "K proportion algo: 67.51\n",
      "Percentage point difference: 11.45\n",
      "Over/under representation 1.2\n",
      "Test passed.\n",
      "\n",
      "--- Foreign Background : 0 ----\n",
      "0 proportion random: 76.31\n",
      "0 proportion algo: 56.87\n",
      "Percentage point difference: -19.45\n",
      "Over/under representation 0.75\n",
      "Test passed.\n",
      "\n",
      "--- Foreign Background : 1 ----\n",
      "1 proportion random: 23.69\n",
      "1 proportion algo: 43.13\n",
      "Percentage point difference: 19.45\n",
      "Over/under representation 1.82\n",
      "Test passed.\n",
      "\n",
      "--- Born Abroad : 0 ----\n",
      "0 proportion random: 79.85\n",
      "0 proportion algo: 62.16\n",
      "Percentage point difference: -17.69\n",
      "Over/under representation 0.78\n",
      "Test passed.\n",
      "\n",
      "--- Born Abroad : 1 ----\n",
      "1 proportion random: 20.15\n",
      "1 proportion algo: 37.84\n",
      "Percentage point difference: 17.69\n",
      "Over/under representation 1.88\n",
      "Test passed.\n",
      "\n",
      "--- Education Level : Low Education ----\n",
      "Low Education proportion random: 52.72\n",
      "Low Education proportion algo: 78.57\n",
      "Percentage point difference: 25.85\n",
      "Over/under representation 1.49\n",
      "Test passed.\n",
      "\n",
      "--- Education Level : High Education ----\n",
      "High Education proportion random: 47.28\n",
      "High Education proportion algo: 21.43\n",
      "Percentage point difference: -25.85\n",
      "Over/under representation 0.45\n",
      "TEST FAILED: PROPORTION HALVED\n",
      "Test failed.\n",
      "\n",
      "--- Income Level : Low Income ----\n",
      "Low Income proportion random: 25.69\n",
      "Low Income proportion algo: 50.83\n",
      "Percentage point difference: 25.13\n",
      "Over/under representation 1.98\n",
      "Test passed.\n",
      "\n",
      "--- Income Level : High Income ----\n",
      "High Income proportion random: 74.31\n",
      "High Income proportion algo: 49.17\n",
      "Percentage point difference: -25.13\n",
      "Over/under representation 0.66\n",
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Runs the first step for the agency's own fairness evaluation \n",
    "\"\"\"\n",
    "def run_fk_test_1(table:pd.DataFrame,column) : \n",
    "\n",
    "    unique_values = table[column].unique()\n",
    "\n",
    "    for category in unique_values : \n",
    "        algorithm_sample = table[table[\"Selection Method\"] != \"Random\"]\n",
    "        random_sample = table[table[\"Selection Method\"] == \"Random\"]\n",
    "\n",
    "        n_class_algo = algorithm_sample[algorithm_sample[column] == category]\n",
    "        n_class_random = random_sample[random_sample[column] == category]\n",
    "\n",
    "        proportion_random = (len(n_class_random) / len(random_sample)) * 100 \n",
    "        proportion_algo =  (len(n_class_algo) / len(algorithm_sample)) * 100 \n",
    "\n",
    "        pass_test = True \n",
    "        print(\"\\n--- {col} : {c} ----\".format(col=column,c=category))\n",
    "        print(category,\"proportion random:\",round(proportion_random,2))\n",
    "        print(category,\"proportion algo:\",round(proportion_algo,2))\n",
    "        print(\"Percentage point difference:\",round(proportion_algo - proportion_random,2))\n",
    "        print(\"Over/under representation\",round(proportion_algo / proportion_random,2))\n",
    "        \n",
    "        if proportion_algo > (2 * proportion_random) : \n",
    "            print(\"PROPORTION DOUBLED\")\n",
    "            pass_test = False \n",
    "        \n",
    "        if proportion_algo < (0.5 * proportion_random) : \n",
    "            print(\"TEST FAILED: PROPORTION HALVED\")\n",
    "            pass_test = False \n",
    "        \n",
    "        if abs(proportion_algo - proportion_random) >= 30 : \n",
    "            print(\"30 PERCENTAGE POINT DIFFERENCE\")\n",
    "            pass_test = False \n",
    "        \n",
    "        if pass_test : \n",
    "            print(\"Test passed.\")\n",
    "        \n",
    "        else : \n",
    "            print(\"Test failed.\")\n",
    "\n",
    "\n",
    "run_fk_test_1(tables[\"Gender 1 Decimal\"],\"Gender\")\n",
    "run_fk_test_1(tables[\"Foreign 1 Decimal\"],\"Foreign Background\")\n",
    "run_fk_test_1(tables[\"Foreign 1 Decimal\"],\"Born Abroad\")\n",
    "run_fk_test_1(tables[\"Education 1 Decimal\"],\"Education Level\")\n",
    "run_fk_test_1(tables[\"Income 1 Decimal\"],\"Income Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gender : M ----\n",
      "M proportion in algorithm sample: 32.49\n",
      "M proportion of errors in algorithm sample: 34.31\n",
      "Percentage point difference: 1.82\n",
      "Test passed.\n",
      "\n",
      "--- Gender : K ----\n",
      "K proportion in algorithm sample: 67.51\n",
      "K proportion of errors in algorithm sample: 65.69\n",
      "Percentage point difference: -1.82\n",
      "Test passed.\n",
      "\n",
      "--- Foreign Background : 0 ----\n",
      "0 proportion in algorithm sample: 56.87\n",
      "0 proportion of errors in algorithm sample: 52.44\n",
      "Percentage point difference: -4.43\n",
      "Test passed.\n",
      "\n",
      "--- Foreign Background : 1 ----\n",
      "1 proportion in algorithm sample: 43.13\n",
      "1 proportion of errors in algorithm sample: 47.56\n",
      "Percentage point difference: 4.43\n",
      "Test passed.\n",
      "\n",
      "--- Born Abroad : 0 ----\n",
      "0 proportion in algorithm sample: 62.16\n",
      "0 proportion of errors in algorithm sample: 58.11\n",
      "Percentage point difference: -4.05\n",
      "Test passed.\n",
      "\n",
      "--- Born Abroad : 1 ----\n",
      "1 proportion in algorithm sample: 37.84\n",
      "1 proportion of errors in algorithm sample: 41.89\n",
      "Percentage point difference: 4.05\n",
      "Test passed.\n",
      "\n",
      "--- Education Level : Low Education ----\n",
      "Low Education proportion in algorithm sample: 78.57\n",
      "Low Education proportion of errors in algorithm sample: 81.23\n",
      "Percentage point difference: 2.66\n",
      "Test passed.\n",
      "\n",
      "--- Education Level : High Education ----\n",
      "High Education proportion in algorithm sample: 21.43\n",
      "High Education proportion of errors in algorithm sample: 18.77\n",
      "Percentage point difference: -2.66\n",
      "Test passed.\n",
      "\n",
      "--- Income Level : Low Income ----\n",
      "Low Income proportion in algorithm sample: 50.83\n",
      "Low Income proportion of errors in algorithm sample: 52.96\n",
      "Percentage point difference: 2.13\n",
      "Test passed.\n",
      "\n",
      "--- Income Level : High Income ----\n",
      "High Income proportion in algorithm sample: 49.17\n",
      "High Income proportion of errors in algorithm sample: 47.04\n",
      "Percentage point difference: -2.13\n",
      "Test passed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs the second step of the agency's own fairness evaluation \n",
    "\"\"\"\n",
    "def run_fk_test_2(table:pd.DataFrame,column) : \n",
    "\n",
    "    unique_values = table[column].unique()\n",
    "\n",
    "    for category in unique_values : \n",
    "        algorithm_sample = table[table[\"Selection Method\"] != \"Random\"]\n",
    "\n",
    "        n_class_algo = len(algorithm_sample[algorithm_sample[column] == category])\n",
    "        \n",
    "        errors_algo = algorithm_sample[algorithm_sample[\"Result\"] != \"No Errors Found\"]\n",
    "        n_errors_class = len(errors_algo[errors_algo[column] == category])\n",
    "\n",
    "        # Proportion of class in the algo sample \n",
    "        prop_class_algo = round((n_class_algo / len(algorithm_sample)) * 100,2)\n",
    "\n",
    "        # Proportion of class in errors in the algo sample \n",
    "        prop_class_errors = round((n_errors_class / len(errors_algo)) * 100,2)\n",
    "\n",
    "        pass_test = True \n",
    "        print(\"\\n--- {col} : {c} ----\".format(col=column,c=category))\n",
    "        print(category,\"proportion in algorithm sample:\",prop_class_algo)\n",
    "        print(category,\"proportion of errors in algorithm sample:\",prop_class_errors)\n",
    "        print(\"Percentage point difference:\",round(prop_class_errors - prop_class_algo,2))\n",
    "        \n",
    "        if abs(prop_class_algo - prop_class_errors) >= 10 : \n",
    "            print(\"BIGGER THAN 10 PERCENT DIFFERENCE\")\n",
    "            pass_test = False \n",
    "        \n",
    "        if pass_test : \n",
    "            print(\"Test passed.\")\n",
    "        \n",
    "        else : \n",
    "            print(\"Test failed.\")\n",
    "\n",
    "run_fk_test_2(tables[\"Gender 1 Decimal\"],\"Gender\")\n",
    "run_fk_test_2(tables[\"Foreign 1 Decimal\"],\"Foreign Background\")\n",
    "run_fk_test_2(tables[\"Foreign 1 Decimal\"],\"Born Abroad\")\n",
    "run_fk_test_2(tables[\"Education 1 Decimal\"],\"Education Level\")\n",
    "run_fk_test_2(tables[\"Income 1 Decimal\"],\"Income Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix() : \n",
    "    def __init__(self,category : str, group : str, table : pd.DataFrame) : \n",
    "        self.category = category\n",
    "        self.group = group \n",
    "       \n",
    "        # Margins \n",
    "        self.predicted_positive_share = None   \n",
    "        self.predicted_negative_share = None \n",
    "        self.actual_positive_share = None \n",
    "        self.actual_negative_share = None \n",
    "\n",
    "        # Cells\n",
    "        self.true_positive_share = None\n",
    "        self.false_positive_share = None\n",
    "        self.true_negative_share = None\n",
    "        self.false_negative_share = None\n",
    "\n",
    "        self.calculate_margins(table)\n",
    "        self.construct_matrix(table)\n",
    "    \n",
    "    def __str__(self) : \n",
    "        output_string = \"\"\"\n",
    "        Confusion Matrix: {category} {title}\n",
    "        TP: {tp} \n",
    "        FP: {fp} \n",
    "        TN: {tn} \n",
    "        FN: {fn} \n",
    "        \"\"\".format(category = self.category,\n",
    "                   title=self.group,\n",
    "                   tp=self.true_positive_share,\n",
    "                   fp=self.false_positive_share,\n",
    "                   tn=self.true_negative_share,\n",
    "                   fn=self.false_negative_share)\n",
    "        \n",
    "        return output_string\n",
    "\n",
    "\n",
    "    def calculate_margins(self,table,total_population_count=850000) : \n",
    "        pass \n",
    "\n",
    "    def construct_matrix(self,table:pd.DataFrame,total_population_count=850000) : \n",
    "\n",
    "        # Split our table into the random sample and non-random sample. \n",
    "        # We'll need these to deduce certain numbers \n",
    "        algorithm_sample = table[table[\"Selection Method\"] != \"Random\"]\n",
    "        random_sample = table[table[\"Selection Method\"] == \"Random\"]\n",
    "        \n",
    "        # Filter our algorithm and random samples for the category (e.g. women) that we are interested in  \n",
    "        algorithm_filtered = algorithm_sample[algorithm_sample[self.category] == self.group]\n",
    "        random_filtered = random_sample[random_sample[self.category] == self.group]\n",
    "\n",
    "        # Calculate the number of x category (e.g. women) in the entire benefit applicant population \n",
    "        # First we get the share of that category in the random sample and then we multiply that by the total size of the benefit applicant population\n",
    "        share_of_class_random = len(random_filtered) / len(random_sample)\n",
    "        class_count_total = int(share_of_class_random * total_population_count)\n",
    "\n",
    "        \"\"\"\n",
    "        In order to infer some of our missing shares, we need to calculate the margins of our confusion matrix \n",
    "        (1) Predicted positive share: The share of predicted positives for category x in the total benefit applicant population\n",
    "        (2) Predicted negative share: The share of predicted negatives for category x in the total benefit applicant population \n",
    "        (3) Actual positive share: The share of actual positives (e.g. true rate of error) for category x \n",
    "        (4) Actual negative share: The share of actual negatives (e.g. true rate of error) for category x \n",
    "        \"\"\"\n",
    "\n",
    "        # Predicted Positive Share:\n",
    "        predicted_positive_count = len(algorithm_filtered)\n",
    "        pred_p_share = predicted_positive_count / class_count_total\n",
    "\n",
    "        # Predicted Negative Share\n",
    "        pred_n_share = 1 - pred_p_share\n",
    "\n",
    "        # Actual P Share \n",
    "        actual_positive_count = len(random_filtered[random_filtered[\"Result\"] == \"Errors Found\"])\n",
    "        class_count_random = len(random_filtered)\n",
    "\n",
    "        actual_p_share = actual_positive_count / class_count_random\n",
    "\n",
    "        # Actual N Share\n",
    "        actual_n_share = 1 - actual_p_share\n",
    "\n",
    "        \"\"\"\n",
    "        Once we have our margins, we derive some of our missing inner cell values. \n",
    "        We can learn our true positive and false positive shares from the algorithm sample \n",
    "        We can then learn our true and false negative shares from subtracting our true and false positive shares\n",
    "        from our actual positive and negative shares (ie. bottom margin)\n",
    "        \"\"\"\n",
    "\n",
    "        # True Positive Share \n",
    "        true_positive_count = len(algorithm_filtered[algorithm_filtered[\"Result\"] == \"Errors Found\"])\n",
    "        true_p_share = true_positive_count / class_count_total \n",
    "\n",
    "        # False Positive Share \n",
    "        false_positive_count = len(algorithm_filtered[algorithm_filtered[\"Result\"] == \"No Errors Found\"])\n",
    "        false_p_share = false_positive_count / class_count_total \n",
    "\n",
    "        # True Negative Share \n",
    "        true_n_share = actual_n_share - false_p_share\n",
    "\n",
    "        # False Negative Share\n",
    "        false_n_share = actual_p_share - true_p_share \n",
    "\n",
    "        # Sanity Check: \n",
    "        assert round(false_n_share + true_n_share,8) == round(pred_n_share,8)\n",
    "\n",
    "        self.predicted_positive_share = pred_p_share \n",
    "        self.predicted_negative_share = pred_n_share\n",
    "\n",
    "        self.true_positive_share = true_p_share \n",
    "        self.false_positive_share = false_p_share\n",
    "        self.true_negative_share = true_n_share\n",
    "        self.false_negative_share = false_n_share\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Confusion Matrix: Gender M\n",
      "        TP: 0.0023001925306670025 \n",
      "        FP: 0.002120782868787271 \n",
      "        TN: 0.6978792171312127 \n",
      "        FN: 0.297699807469333 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Gender K\n",
      "        TP: 0.003451879333210227 \n",
      "        FP: 0.0037477547046282462 \n",
      "        TN: 0.7032369130977567 \n",
      "        FN: 0.28956345286440477 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Foreign Background 0\n",
      "        TP: 0.002024166669236058 \n",
      "        FP: 0.002431158291991823 \n",
      "        TN: 0.7197215325715877 \n",
      "        FN: 0.2758231424671845 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Foreign Background 1\n",
      "        TP: 0.00591545518210761 \n",
      "        FP: 0.004971763759269285 \n",
      "        TN: 0.6401895265633113 \n",
      "        FN: 0.34892325449531175 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Income Level High Income\n",
      "        TP: 0.0018650631556615274 \n",
      "        FP: 0.0020914672569005755 \n",
      "        TN: 0.7254149594783179 \n",
      "        FN: 0.2706285101091199 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Income Level Low Income\n",
      "        TP: 0.006071845593790782 \n",
      "        FP: 0.005755889827598049 \n",
      "        TN: 0.6299318425144094 \n",
      "        FN: 0.3582404220642018 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Education Level High Education\n",
      "        TP: 0.001169555718132095 \n",
      "        FP: 0.0015403297649441848 \n",
      "        TN: 0.7600758318512174 \n",
      "        FN: 0.2372142826657063 \n",
      "        \n",
      "\n",
      "        Confusion Matrix: Education Level Low Education\n",
      "        TP: 0.004538790593055249 \n",
      "        FP: 0.004371431057913094 \n",
      "        TN: 0.6478024819855652 \n",
      "        FN: 0.3432872963634665 \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "confusion_matrices = {}\n",
    "\n",
    "confusion_matrices[\"Gender\"] = {\n",
    "    \"Men\": ConfusionMatrix(\"Gender\",\"M\",tables[\"Gender 1 Decimal\"]),\n",
    "    \"Women\": ConfusionMatrix(\"Gender\",\"K\",tables[\"Gender 1 Decimal\"])\n",
    "    }\n",
    "\n",
    "confusion_matrices[\"Foreign Background\"] = {\n",
    "    \"Swedish\": ConfusionMatrix(\"Foreign Background\",0,tables[\"Foreign 1 Decimal\"]),\n",
    "    \"Foreign\": ConfusionMatrix(\"Foreign Background\",1,tables[\"Foreign 1 Decimal\"])\n",
    "    }\n",
    "\n",
    "confusion_matrices[\"Income\"] = {\n",
    "    \"High Income\": ConfusionMatrix(\"Income Level\",\"High Income\",tables[\"Income 1 Decimal\"]),\n",
    "    \"Low Income\": ConfusionMatrix(\"Income Level\",\"Low Income\",tables[\"Income 1 Decimal\"])\n",
    "    }\n",
    "\n",
    "confusion_matrices[\"Education\"] = {\n",
    "    \"High Education\": ConfusionMatrix(\"Education Level\",\"High Education\",tables[\"Education 1 Decimal\"]),\n",
    "    \"Low Education\": ConfusionMatrix(\"Education Level\",\"Low Education\",tables[\"Education 1 Decimal\"])\n",
    "    }\n",
    "\n",
    "for c in confusion_matrices.keys() : \n",
    "    for m in confusion_matrices[c].keys() : \n",
    "        print(confusion_matrices[c][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Predictive Parity Gender =======\n",
      "Men : 0.52\n",
      "Women : 0.48\n",
      "The model is 1.0833333333333335 times less / more accurate for Men than Women\n",
      "\n",
      "======= Predictive Parity Foreign Background =======\n",
      "Swedish : 0.45\n",
      "Foreign : 0.54\n",
      "The model is 0.8333333333333333 times less / more accurate for Swedish than Foreign\n",
      "\n",
      "======= Predictive Parity Income Level =======\n",
      "High Income : 0.47\n",
      "Low Income : 0.51\n",
      "The model is 0.9215686274509803 times less / more accurate for High Income than Low Income\n",
      "\n",
      "======= Predictive Parity Education Level =======\n",
      "High Education : 0.43\n",
      "Low Education : 0.51\n",
      "The model is 0.8431372549019608 times less / more accurate for High Education than Low Education\n"
     ]
    }
   ],
   "source": [
    "def test_predictive_parity(category:dict) :   \n",
    "    keys = list(category.keys())\n",
    "    accuracy_rates = []  \n",
    "\n",
    "    print(\"\\n======= Predictive Parity {c} =======\".format(c = category[keys[0]].category))\n",
    "\n",
    "    for group_name,conf_matrix in category.items() : \n",
    "        accuracy_rate = round(conf_matrix.true_positive_share / conf_matrix.predicted_positive_share,2)\n",
    "        print(group_name,\":\",accuracy_rate)\n",
    "        \n",
    "        accuracy_rates.append(accuracy_rate) \n",
    "    \n",
    "    print(\"The model is {i} times less / more accurate for {c1} than {c2}\".format(\n",
    "        i = accuracy_rates[0] / accuracy_rates[1],\n",
    "        c1 = keys[0],\n",
    "        c2 = keys[1]\n",
    "    ))\n",
    "\n",
    "test_predictive_parity(confusion_matrices[\"Gender\"])\n",
    "test_predictive_parity(confusion_matrices[\"Foreign Background\"])\n",
    "test_predictive_parity(confusion_matrices[\"Income\"])\n",
    "test_predictive_parity(confusion_matrices[\"Education\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= False Positive Error Rate Balance Gender =======\n",
      "Men : 0.003\n",
      "Women : 0.0053\n",
      "An innocent Women is 1.7666666666666666 times more / less likely to be wrongly flagged than an innocent Men\n",
      "\n",
      "======= False Positive Error Rate Balance Foreign Background =======\n",
      "Swedish : 0.0034\n",
      "Foreign : 0.0077\n",
      "An innocent Foreign is 2.2647058823529416 times more / less likely to be wrongly flagged than an innocent Swedish\n",
      "\n",
      "======= False Positive Error Rate Balance Income Level =======\n",
      "High Income : 0.0029\n",
      "Low Income : 0.0091\n",
      "An innocent Low Income is 3.137931034482759 times more / less likely to be wrongly flagged than an innocent High Income\n",
      "\n",
      "======= False Positive Error Rate Balance Education Level =======\n",
      "High Education : 0.002\n",
      "Low Education : 0.0067\n",
      "An innocent Low Education is 3.35 times more / less likely to be wrongly flagged than an innocent High Education\n"
     ]
    }
   ],
   "source": [
    "def test_false_positive_error_rate(category:dict) : \n",
    "    keys = list(category.keys())\n",
    "    error_rates = []  \n",
    "\n",
    "    print(\"\\n======= False Positive Error Rate Balance {c} =======\".format(c = category[keys[0]].category))\n",
    "\n",
    "    for group_name,conf_matrix in category.items() : \n",
    "        error_rate = round(conf_matrix.false_positive_share / (conf_matrix.false_positive_share + conf_matrix.true_negative_share),4)\n",
    "        \n",
    "        print(group_name,\":\",error_rate)\n",
    "\n",
    "        error_rates.append(error_rate) \n",
    "    \n",
    "    print(\"An innocent {c1} is {i} times more / less likely to be wrongly flagged than an innocent {c2}\".format(\n",
    "        i = (error_rates[1] / error_rates[0]),\n",
    "        c1 = keys[1],\n",
    "        c2 = keys[0]\n",
    "    ))\n",
    "\n",
    "test_false_positive_error_rate(confusion_matrices[\"Gender\"])\n",
    "test_false_positive_error_rate(confusion_matrices[\"Foreign Background\"])\n",
    "test_false_positive_error_rate(confusion_matrices[\"Income\"])\n",
    "test_false_positive_error_rate(confusion_matrices[\"Education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= False Negative Balance Gender =======\n",
      "FNR 0.9923326915644434 Men\n",
      "FNR 0.9882194583221255 Women\n",
      "The model is 1.004162267002212 times less / more accurate for Men than Women\n",
      "\n",
      "======= False Negative Balance Foreign Background =======\n",
      "FNR 0.9927148235643262 Swedish\n",
      "FNR 0.9833291717595148 Foreign\n",
      "The model is 1.0095447710434717 times less / more accurate for Swedish than Foreign\n",
      "\n",
      "======= False Negative Balance Income Level =======\n",
      "FNR 0.9931555701174307 High Income\n",
      "FNR 0.9833334034211254 Low Income\n",
      "The model is 1.00998864338599 times less / more accurate for High Income than Low Income\n",
      "\n",
      "======= False Negative Balance Education Level =======\n",
      "FNR 0.9950938128773272 High Education\n",
      "FNR 0.9869509770449663 Low Education\n",
      "The model is 1.008250496753893 times less / more accurate for High Education than Low Education\n"
     ]
    }
   ],
   "source": [
    "def false_negative_balance(category:dict) : \n",
    "    keys = list(category.keys())\n",
    "    accuracy_rates = []  \n",
    "\n",
    "    print(\"\\n======= False Negative Balance {c} =======\".format(c = category[keys[0]].category))\n",
    "\n",
    "    fnr_rates = []\n",
    "    for group_name,conf_matrix in category.items() : \n",
    "\n",
    "        fnr = conf_matrix.false_negative_share / (conf_matrix.false_negative_share + conf_matrix.true_positive_share)\n",
    "\n",
    "        print(\"FNR\",fnr,group_name)\n",
    "\n",
    "        fnr_rates.append(fnr)\n",
    "    \n",
    "    print(\"The model is {i} times less / more accurate for {c1} than {c2}\".format(\n",
    "        i = fnr_rates[0] / fnr_rates[1],\n",
    "        c1 = keys[0],\n",
    "        c2 = keys[1]\n",
    "    ))\n",
    "\n",
    "false_negative_balance(confusion_matrices[\"Gender\"])\n",
    "false_negative_balance(confusion_matrices[\"Foreign Background\"])\n",
    "false_negative_balance(confusion_matrices[\"Income\"])\n",
    "false_negative_balance(confusion_matrices[\"Education\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= False Discovery Rate Gender =======\n",
      "False Discovery Rate 0.5202907328891581 Men\n",
      "False Discovery Rate 0.4794520547945205 Women\n",
      "The model is 1.0851778143116726 times less / more accurate for Men than Women\n",
      "\n",
      "======= False Discovery Rate Foreign Background =======\n",
      "False Discovery Rate 0.4543252595155709 Swedish\n",
      "False Discovery Rate 0.5433394160583941 Foreign\n",
      "The model is 0.8361720981176587 times less / more accurate for Swedish than Foreign\n",
      "\n",
      "======= False Discovery Rate Income Level =======\n",
      "False Discovery Rate 0.47138855542216884 High Income\n",
      "False Discovery Rate 0.5133565621370499 Low Income\n",
      "The model is 0.9182478421232746 times less / more accurate for High Income than Low Income\n",
      "\n",
      "======= False Discovery Rate Education Level =======\n",
      "False Discovery Rate 0.4315886134067952 High Education\n",
      "False Discovery Rate 0.5093914350112697 Low Education\n",
      "The model is 0.8472631923959357 times less / more accurate for High Education than Low Education\n"
     ]
    }
   ],
   "source": [
    "def false_discovery_rate(category:dict) : \n",
    "    keys = list(category.keys())\n",
    "    accuracy_rates = []  \n",
    "\n",
    "    print(\"\\n======= False Discovery Rate {c} =======\".format(c = category[keys[0]].category))\n",
    "\n",
    "    fnr_rates = []\n",
    "    for group_name,conf_matrix in category.items() : \n",
    "\n",
    "        fnr = conf_matrix.true_positive_share / (conf_matrix.false_positive_share + conf_matrix.true_positive_share)\n",
    "\n",
    "        print(\"False Discovery Rate\",fnr,group_name)\n",
    "\n",
    "        fnr_rates.append(fnr)\n",
    "    \n",
    "    print(\"The model is {i} times less / more accurate for {c1} than {c2}\".format(\n",
    "        i = fnr_rates[0] / fnr_rates[1],\n",
    "        c1 = keys[0],\n",
    "        c2 = keys[1]\n",
    "    ))\n",
    "\n",
    "false_discovery_rate(confusion_matrices[\"Gender\"])\n",
    "false_discovery_rate(confusion_matrices[\"Foreign Background\"])\n",
    "false_discovery_rate(confusion_matrices[\"Income\"])\n",
    "false_discovery_rate(confusion_matrices[\"Education\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fd_diff(cm_group0, cm_group1):\n",
    "    fdr_0 = cm_group0.false_positive_share/(cm_group0.false_positive_share+cm_group0.true_positive_share)\n",
    "    fdr_1 = cm_group1.false_positive_share/(cm_group1.false_positive_share+cm_group1.true_positive_share)\n",
    "    return fdr_0 - fdr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fn_diff(cm_group0, cm_group1):\n",
    "    fnr_0 = cm_group0.false_negative_share/(cm_group0.false_negative_share + cm_group0.true_positive_share)\n",
    "    fnr_1 = cm_group1.false_negative_share/(cm_group1.false_negative_share + cm_group1.true_positive_share)\n",
    "    return fnr_0 - fnr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fp_diff(cm_group0, cm_group1):\n",
    "    fpr_0 = cm_group0.false_positive_share/(cm_group0.false_positive_share + cm_group0.true_negative_share)\n",
    "    fpr_1 = cm_group1.false_positive_share/(cm_group1.false_positive_share + cm_group1.true_negative_share)\n",
    "    return fpr_0 - fpr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_diff(cm_group0, cm_group1):\n",
    "    precision_0 = cm_group0.true_positive_share/(cm_group0.true_positive_share + cm_group0.false_positive_share)\n",
    "    precision_1 = cm_group1.true_positive_share/(cm_group1.true_positive_share + cm_group1.false_positive_share)\n",
    "    return precision_0 - precision_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sp_diff(cm_group0, cm_group1):\n",
    "    ppr_0 = cm_group0.true_positive_share + cm_group0.false_positive_share\n",
    "    ppr_1 = cm_group1.true_positive_share + cm_group1.false_positive_share\n",
    "    return ppr_0 - ppr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "['M' 'K']\n",
      "Income Level\n",
      "['Low Income' 'High Income']\n",
      "Education Level\n",
      "['Low Education' 'High Education']\n",
      "Foreign Background\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "def bootstrap(cur_df, iterations = 10, metrics = [], seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    cur_cols = cur_df.columns\n",
    "    cur_group = cur_cols[-1]\n",
    "    print(cur_group)\n",
    "    \n",
    "    cur_group_values = cur_df[cur_group].unique()\n",
    "    print(cur_group_values)\n",
    "\n",
    "    #set up metrics data frame\n",
    "    groups_list = ['category', 'group0', 'group1']\n",
    "    metrics_df = pd.DataFrame(columns=groups_list + metrics)\n",
    "    \n",
    "    sample_size = cur_df.shape[0]\n",
    "    #loop over num iterations\n",
    "    for i in range(iterations):\n",
    "        #sample with replacement from cur_df\n",
    "        sample_df = cur_df.sample(n = sample_size, replace = True)\n",
    "        \n",
    "        #subset sample_df by cur_group_values\n",
    "        sample_df_group0 = sample_df[sample_df[cur_group] == cur_group_values[0]]\n",
    "        sample_df_group1 = sample_df[sample_df[cur_group] == cur_group_values[1]]\n",
    "        \n",
    "        #get confusion matrices for both dfs\n",
    "        cm_group0 = ConfusionMatrix(cur_group, cur_group_values[0], sample_df_group0)\n",
    "        cm_group1 = ConfusionMatrix(cur_group, cur_group_values[1], sample_df_group1)\n",
    "        \n",
    "        new_metrics_row = {}\n",
    "        new_metrics_row['category'] = cur_group\n",
    "        new_metrics_row['group0'] = cur_group_values[0]\n",
    "        new_metrics_row['group1'] = cur_group_values[1]\n",
    "        \n",
    "        #calculate metrics\n",
    "        for cur_metric in metrics:\n",
    "            if cur_metric == 'false_discovery_rate':\n",
    "                new_metrics_row[cur_metric] = calc_fd_diff(cm_group0, cm_group1)\n",
    "            elif cur_metric == 'false_negative_balance':\n",
    "                new_metrics_row[cur_metric] = calc_fn_diff(cm_group0, cm_group1)\n",
    "            elif cur_metric == 'false_positive_error_rate':\n",
    "                new_metrics_row[cur_metric] = calc_fp_diff(cm_group0, cm_group1)\n",
    "            elif cur_metric == 'test_predictive_parity':\n",
    "                new_metrics_row[cur_metric] = calc_precision_diff(cm_group0, cm_group1)\n",
    "            elif cur_metric == 'statistical_parity':\n",
    "                new_metrics_row[cur_metric] = calc_sp_diff(cm_group0, cm_group1)\n",
    "        \n",
    "        #add metrics to metrics data frame\n",
    "        metrics_df.loc[len(metrics_df)] = new_metrics_row\n",
    "    \n",
    "    #set up results df\n",
    "    results_df = pd.DataFrame(columns = ['metric', 'mean', 'se', 'gt_zero', 'st_zero', 'conf_low', 'conf_high'])\n",
    "    \n",
    "    #calculate mean, sd, and p.values for each metric\n",
    "    for cur_metric in metrics:\n",
    "        new_results_row = {}\n",
    "        new_results_row['metric'] = cur_metric\n",
    "        new_results_row['mean'] = metrics_df.loc[:,cur_metric].mean(skipna = True)\n",
    "        new_results_row['se'] = metrics_df.loc[:,cur_metric].std(skipna = True)\n",
    "        new_results_row['gt_zero'] = (metrics_df.loc[:,cur_metric] > 0).mean(skipna = True)\n",
    "        new_results_row['st_zero'] = (metrics_df.loc[:,cur_metric] < 0).mean(skipna = True)\n",
    "        new_results_row['conf_low'] = metrics_df.loc[:,cur_metric].quantile(0.05) #CHECK\n",
    "        new_results_row['conf_high'] = metrics_df.loc[:,cur_metric].quantile(0.95) #CHECL\n",
    "        results_df.loc[len(results_df)] = new_results_row\n",
    "    \n",
    "    \n",
    "    return cur_group, metrics_df, results_df\n",
    "\n",
    "mymetrics = ['false_discovery_rate', 'false_negative_balance', 'false_positive_error_rate', \n",
    "             'test_predictive_parity', 'statistical_parity']\n",
    "\n",
    "n_samples = 10000\n",
    "for key in tables:\n",
    "    cur_group, metrics_df, results_df = bootstrap(tables[key], n_samples, mymetrics, 12345)\n",
    "    metrics_df.to_excel('bootstrapping_results/resampling_results_' + cur_group + '.xlsx', index = False)\n",
    "    results_df.to_excel('bootstrapping_results/summary_stats_' + cur_group + '.xlsx', index = False)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
